## General Guidance  

## Framework of ML  

![image-20220208202740253](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20220208202740253.png)

![image-20220208203106918](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20220208203106918.png)

执行助教的sample code 就可以过baseline，如果想要做的更好，要怎么办呢？  

![image-20220208203402511](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20220208203402511.png)

如果你觉得你的模型结果不好，先去检查loss on training data，是不是训练数据你就没学好？如果loss很大，那么就看看model bias  

有可能是你的function set太小了，能获得small loss的function根本就不在你的搜索范围内，就算你在你那抠嗦的function set 里找出了最优，也无济于事。  怎么办？  

重新设计你的model ，给它更大的flexible。  

怎么增加model的弹性？
1. more features
2. deep learning (more neurons,layers)  

![image-20220208204652319](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20220208204652319.png)

但是training data loss 并不一定是model bias造成的，可能是优化不到位造成的  

看到 P10 08：07

## Optimization Issue  
本门课程只会用到gradient descent 这种optimization 这种方法。这种方法有很多问题，比如你可能卡在local minima处，没有办法找到一个真的让loss低的参数，
（之前说卡在local minima处是一个假问题的前提是，数据足够多，解空间比较小，从而局部极值点比较少？（弹幕））  

对应到图里，意思就是蓝色的function set中确实有loss比较低的点（橙色点），但gradient descent 没有办法帮我们找到这一点。  

gradient descent给到你$\theta^*$ 就结束了，但它的loss不够低  

![image-20220209191247990](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20220209191247990.png)

那么问题来了，当我们发现training data 的loss大时，到底是因为Model bias,我们模型的弹性不够，我们的海里面没有针， 还是optimization issue，我们模型的弹性够了，针在海里，但gradient descent 不给力，没办法找到海里的针。  
或者说我们的function set 已经足够大了，还是不够大。  



![image-20220209191942124](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20220209191942124.png)

建议的方法就是通过比较不同的模型，来判断你的model够不够大。  

**Residual network**的paper(2015年的): http://arxiv.org/abs/1512.03385  

![image-20220209192544461](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20220209192544461.png)

你再测试集上发现56-layer network效果不如20-layer的network，不要着急下判断说这是overfitting，去看看训练集，56-layer效果依然比20-layer差，56层模型弹性肯定比20层好，所以不是model bias,是optimization issue。  

## Optimization Issue  
* Gaining the insights from comparison
* Start from shallower networks(or other models),which are easier to optimize.  

你怎么知道你的optimization有没有做好呢？ 看到一个你从来没有做过的问题，你可以先跑一些比较小，比较浅的network，或甚至用一些不是deep learning 的方法，linear model ，support vector machine, 这些方法是比较容易做optimize的，不太会有optimizaton失败的问题。  

* if deeper networks do not obtain smaller loss on **training data**,then there is optimization issue.  

![image-20220209193904281](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20220209193904281.png)
比如这个例子，就是optimization issue.  

optimization 做的不好的话 怎么办呢？  
* Solution:More powerful optimization technology (next lecture)  

现在假设经过努力已经可以使你的training data的loss变小了，接下来就可以看testing data的loss  

training data的loss小，testing data的loss大，才叫做overfitting。  

## Overfitting  
* Small loss on training data, large loss on testing data.Why?  

来看这个一无是处的方法：数据库学习法 database learning （简称也是DL）

![image-20220209195148994](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20220209195148994.png)

过拟合 过于拟合训练样本而对其他测试样本的泛化能力不够。  (弹幕）  

一般来说，模型弹性过强，在没有给出训练值的地方就会模拟过了。  

overfitting背后的数学原理  龙格（Runge）现象？（弹幕）  

![image-20220209200303884](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20220209200303884.png)
换言之，当你只有比较少的数据时，就不要把模型搞太复杂。

怎么解决overfitting的问题呢？有两个方向：  
1. 往往是最有效的方向：增加训练资料
p10 21:39
Data augmentation 数据增强
利用你对问题的理解创造出新的资料，比如，做影像辨识里，很常用的一招，把一个图片左右翻转，或其中一块截出来，  
但要注意的是，augment要有道理，比如影像辨识中，不会有人把照片倒过来。

![image-20220209222218184](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20220209222218184.png)

2. 给你的模型一些限制
增加资料是一种方法，另一种方法是不要让你的模型有那么大的弹性，给它一些限制，比如，限制我们的model一定是一条二次曲线，

![image-20220209222721741](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20220209222721741.png)

* Less parameters, sharing parameters    比较少的神经元个数  

    fully-connected neural network 其实是一个比较有弹性的架构，而CNN是一个比较有限制的架构，它厉害的地方在于针对影像的特性来限制模型的弹性，

![image-20220209223201694](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20220209223201694.png)
* Less features
* Early stopping
* Regularization
* Dropout  

但是呢，也不能说给模型太大的限制，

![image-20220209223629112](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20220209223629112.png)

![image-20220209223930360](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20220209223930360.png)

怎么停在上图那个没有overfitting的位置呢？  

很直觉的做法，就是把不同复杂度的模型分别传到kaggle上，看mse是多少。  

这种"面向public test编程/在测试集上调参"的方法不一定靠谱：  

![image-20220209224600721](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20220209224600721.png)


为啥测试集要分public 和 private  

因为你可以做一个model输出随机结果，只要你试得足够多次，几亿兆次，它很可能在public testing set上取得很好结果，但同样的模型基本不可能在private set上也取得好成绩。  

![image-20220209225647237](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20220209225647237.png)

所以不要用public testing set 去调你的模型，因为你可能败在private Set上。  

所以到底要怎么做来选择model 才是合理的呢？  

不建议用public测试集调结果，因为又会导致败在private testing set上。  
最好的做法就是挑Validation set 上loss最小的就好了，你不用去管public testing set 的结果，

![image-20220209231011757](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20220209231011757.png)

那么怎么划分 training set 和 validation set 呢  

## N-fold Cross Validation  
k折交叉验证

有个弹幕说，如果选好了合适的model训练方法，就把validation set 也放进去训练，这样会提高分数。  它说的是对的，和老师讲的一样  

![image-20220209231555943](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20220209231555943.png)

最后除了overfitting，还有一种small loss on training data, large loss on testing data 的情况，叫 mismatch ，你也可以说它是一种overfitting ,  
例子是啥，预测机器学习视频点阅数，按理周五晚上按历史规律大家都出去玩没人学习，点阅量会迎来低谷，但提前告诉大家关注那天的点约束，结果很多人故意去点阅，导致实际不但不是低谷，而且是峰值，这就是mismatch  

一般的overfitting你可以通过搜集更多资料来克服，但mismatch是说你的训练资料和测试资料的分布是不一样的，训练资料再增加也于事无补，

![image-20220209232556890](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20220209232556890.png)

完结撒花 🌺
