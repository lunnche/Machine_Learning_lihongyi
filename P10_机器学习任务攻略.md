## General Guidance  

## Framework of ML  

![image-20220208202740253](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20220208202740253.png)

![image-20220208203106918](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20220208203106918.png)

执行助教的sample code 就可以过baseline，如果想要做的更好，要怎么办呢？  

![image-20220208203402511](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20220208203402511.png)

如果你觉得你的模型结果不好，先去检查loss on training data，是不是训练数据你就没学好？如果loss很大，那么就看看model bias  

有可能是你的function set太小了，能获得small loss的function根本就不在你的搜索范围内，就算你在你那抠嗦的function set 里找出了最优，也无济于事。  怎么办？  

重新设计你的model ，给它更大的flexible。  

怎么增加model的弹性？
1. more features
2. deep learning (more neurons,layers)  

![image-20220208204652319](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20220208204652319.png)

但是training data loss 并不一定是model bias造成的，可能是优化不到位造成的  

看到 P10 08：07

## Optimization Issue  
本门课程只会用到gradient descent 这种optimization 这种方法。这种方法有很多问题，比如你可能卡在local minima处，没有办法找到一个真的让loss低的参数，
（之前说卡在local minima处是一个假问题的前提是，数据足够多，解空间比较小，从而局部极值点比较少？（弹幕））  

对应到图里，意思就是蓝色的function set中确实有loss比较低的点（橙色点），但gradient descent 没有办法帮我们找到这一点。  

gradient descent给到你$\theta^*$ 就结束了，但它的loss不够低  

![image-20220209191247990](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20220209191247990.png)

那么问题来了，当我们发现training data 的loss大时，到底是因为Model bias,我们模型的弹性不够，我们的海里面没有针， 还是optimization issue，我们模型的弹性够了，针在海里，但gradient descent 不给力，没办法找到海里的针。  
或者说我们的function set 已经足够大了，还是不够大。  



![image-20220209191942124](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20220209191942124.png)

建议的方法就是通过比较不同的模型，来判断你的model够不够大。  

**Residual network**的paper(2015年的): http://arxiv.org/abs/1512.03385  

![image-20220209192544461](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20220209192544461.png)

你再测试集上发现56-layer network效果不如20-layer的network，不要着急下判断说这是overfitting，去看看训练集，56-layer效果依然比20-layer差，56层模型弹性肯定比20层好，所以不是model bias,是optimization issue。  

## Optimization Issue  
* Gaining the insights from comparison
* Start from shallower networks(or other models),which are easier to optimize.  

你怎么知道你的optimization有没有做好呢？ 看到一个你从来没有做过的问题，你可以先跑一些比较小，比较浅的network，或甚至用一些不是deep learning 的方法，linear model ，support vector machine, 这些方法是比较容易做optimize的，不太会有optimizaton失败的问题。  

* if deeper networks do not obtain smaller loss on **training data**,then there is optimization issue.  

![image-20220209193904281](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20220209193904281.png)
比如这个例子，就是optimization issue.  

optimization 做的不好的话 怎么办呢？  
* Solution:More powerful optimization technology (next lecture)  

现在假设经过努力已经可以使你的training data的loss变小了，接下来就可以看testing data的loss  

training data的loss小，testing data的loss大，才叫做overfitting。  

## Overfitting  
* Small loss on training data, large loss on testing data.Why?  

来看这个一无是处的方法：数据库学习法 database learning （简称也是DL）

![image-20220209195148994](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20220209195148994.png)

过拟合 过于拟合训练样本而对其他测试样本的泛化能力不够。  (弹幕）  

一般来说，模型弹性过强，在没有给出训练值的地方就会模拟过了。  

overfitting背后的数学原理  龙格（Runge）现象？（弹幕）  

![image-20220209200303884](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20220209200303884.png)
换言之，当你只有比较少的数据时，就不要把模型搞太复杂。

怎么解决overfitting的问题呢？有两个方向：  
1. 往往是最有效的方向：增加训练资料
p10 21:39
